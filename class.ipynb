{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there's problems here, update fastai and torch to latest versions\n",
    "# pip install 'name' == 'version'\n",
    "# fastbook needed for bing_image_search\n",
    "# widgets needed for cleaner\n",
    "import dotenv\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "\n",
    "# remember to set dls.device = device and learn.model.to(device)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# load environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# use Azure search key\n",
    "image_key = os.getenv('AZURE_IMAGE_SEARCH_KEY')\n",
    "\n",
    "if not image_key:\n",
    "    raise Exception(\"Set azure key in environment\")\n",
    "\n",
    "# search up images, probably needs a more specific search...\n",
    "# kaguya_images = search_images_bing(image_key, 'Shinomiya Kaguya')\n",
    "# ims = kaguya_images.attrgot('contentUrl')\n",
    "\n",
    "# looking at an image\n",
    "# dest = 'images/kaguya.jpg'\n",
    "# download_url(ims[0], dest)\n",
    "# im = Image.open(dest)\n",
    "# im.to_thumb(128,128)\n",
    "\n",
    "characters = ['shinomiya kaguya', \n",
    "              'miyuki shirogane', \n",
    "              'fujiwara chika', \n",
    "              'yu ishigami', \n",
    "              'miko iino', \n",
    "              'ai hayasaka', \n",
    "              'shirogane kei']\n",
    "path = Path('kaguyasama images')\n",
    "\n",
    "# make folders for characters\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in characters:\n",
    "        dest = path/o \n",
    "        dest.mkdir(exist_ok = True) # ok if exists, leave unaltered\n",
    "        results = search_images_bing(image_key, f\"{o}\") # search images\n",
    "        urls = results.attrgot('contentUrl') # get list of urls for images\n",
    "        download_images(dest, urls=urls) # download images into characters folder\n",
    "\n",
    "# get image files and unlink failed ones\n",
    "images = get_image_files(path)\n",
    "failed = verify_images(fns = images)\n",
    "failed.map(Path.unlink)\n",
    "\n",
    "# just checking the number of images which remain after the carnage\n",
    "# for o in characters:\n",
    "#     img_list = os.listdir(path/o)\n",
    "#     print(f'{o}: {len(img_list)}')\n",
    "\n",
    "# converting all images to jpg\n",
    "for o in characters:\n",
    "    for root, dirs, files in os.walk(path/o):\n",
    "        for f in files:\n",
    "            if not (f.endswith(\".jpg\") or f.endswith(\".png\")):\n",
    "                Path.unlink(path/o/f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make DataBlock\n",
    "# input: images, output: categories (name)\n",
    "# retrieve input images by calling get_image_files\n",
    "# do random split with 20% as validation data, make seed random later\n",
    "# get answer by the name of the folder the image is in (parent_label)\n",
    "chars = DataBlock(\n",
    "    blocks = (ImageBlock, CategoryBlock),\n",
    "    get_items = get_image_files,\n",
    "    splitter = RandomSplitter(valid_pct = 0.2, seed = 42),\n",
    "    get_y = parent_label,\n",
    "    item_tfms = RandomResizedCrop(224, min_scale = 0.5),\n",
    "    batch_tfms = aug_transforms()\n",
    ")\n",
    "\n",
    "# make DataLoader from DataBlock, pass path data into the dataloader\n",
    "dls = chars.dataloaders(path)\n",
    "\n",
    "# learn with resnet18\n",
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of results\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
